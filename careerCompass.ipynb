{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed and saved: Datasets/Salaries/filtered_occupation_data_2020.csv\n",
      "✅ Processed and saved: Datasets/Salaries/filtered_occupation_data_2021.csv\n",
      "✅ Processed and saved: Datasets/Salaries/filtered_occupation_data_2023.csv\n",
      "✅ Processed and saved: Datasets/Salaries/filtered_occupation_data_2024.csv\n",
      "✅ Processed and saved: Datasets/Salaries/filtered_occupation_data_2019.csv\n",
      "✅ Processed and saved: Datasets/Salaries/filtered_occupation_data_2016.csv\n",
      "✅ Processed and saved: Datasets/Salaries/filtered_occupation_data_2018.csv\n",
      "✅ Processed and saved: Datasets/Salaries/filtered_occupation_data_2017.csv\n",
      "✅ Processed and saved: Datasets/Salaries/filtered_occupation_data_2022.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Define input and output folders\n",
    "input_folder = \"Datasets/salary\"\n",
    "output_folder = \"Datasets/Salaries\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Required columns in lowercase\n",
    "required_columns = [\n",
    "    \"occ_code\", \"occ_title\", \"area_title\",\n",
    "    \"naics_title\", \"a_median\", \"a_pct10\", \"a_pct90\"\n",
    "]\n",
    "\n",
    "# Get all Excel files from the folder\n",
    "excel_files = glob(os.path.join(input_folder, \"*.xlsx\"))\n",
    "\n",
    "# Process each file\n",
    "for file_path in excel_files:\n",
    "    try:\n",
    "        filename = os.path.basename(file_path)\n",
    "        year = next((part for part in filename.split('_') if part.isdigit()), None)\n",
    "\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        # Convert column names to lowercase\n",
    "        df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "        # Add year column\n",
    "        df[\"year\"] = year\n",
    "\n",
    "        # Reorder and filter columns (now all lowercase)\n",
    "        filtered_df = df[required_columns + [\"year\"]]\n",
    "\n",
    "        # Write to CSV\n",
    "        output_path = os.path.join(output_folder, f\"filtered_occupation_data_{year}.csv\")\n",
    "        filtered_df.to_csv(output_path, index=False)\n",
    "\n",
    "        # Uncomment for debug:\n",
    "        print(f\"✅ Processed and saved: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found salary files: ['filtered_occupation_data_2016.csv', 'filtered_occupation_data_2017.csv', 'filtered_occupation_data_2018.csv', 'filtered_occupation_data_2019.csv', 'filtered_occupation_data_2020.csv', 'filtered_occupation_data_2021.csv', 'filtered_occupation_data_2022.csv', 'filtered_occupation_data_2023.csv', 'filtered_occupation_data_2024.csv']\n",
      "✅ Done! Output written to 'soc_compiled_output.csv' with 1550 SOC records.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Directory containing salary_data_2016.csv to salary_data_2024.csv\n",
    "dataset_dir = \"Datasets/\"\n",
    "salary_dir = f\"{dataset_dir}Salaries/\"\n",
    "salary_files = sorted(glob(os.path.join(salary_dir, \"filtered_occupation_data_*.csv\")))\n",
    "\n",
    "# Check if salary files exist\n",
    "if not salary_files:\n",
    "    raise FileNotFoundError(\"❌ No salary_data_*.csv files found in the current directory.\")\n",
    "\n",
    "print(f\"✅ Found salary files: {[os.path.basename(f) for f in salary_files]}\")\n",
    "\n",
    "# Load all salary CSVs\n",
    "salary_dfs = []\n",
    "for file in salary_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        df[\"YEAR\"] = int(file.split(\"_\")[-1].split(\".\")[0])\n",
    "        salary_dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading {file}: {e}\")\n",
    "\n",
    "salary_df = pd.concat(salary_dfs, ignore_index=True)\n",
    "\n",
    "# Load education and skills\n",
    "education_df = pd.read_csv(os.path.join(dataset_dir, \"education_data.csv\"))\n",
    "skills_df = pd.read_csv(os.path.join(dataset_dir, \"skills_data.csv\"))\n",
    "\n",
    "# Ensure salary columns are numeric before division\n",
    "salary_df[\"a_pct10\"] = pd.to_numeric(salary_df[\"a_pct10\"], errors=\"coerce\")\n",
    "salary_df[\"a_median\"] = pd.to_numeric(salary_df[\"a_median\"], errors=\"coerce\")\n",
    "salary_df[\"a_pct90\"] = pd.to_numeric(salary_df[\"a_pct90\"], errors=\"coerce\")\n",
    "\n",
    "# Convert annual to monthly\n",
    "salary_df[\"M_PCT10\"] = (salary_df[\"a_pct10\"] / 12).round(2)\n",
    "salary_df[\"M_MEDIAN\"] = (salary_df[\"a_median\"] / 12).round(2)\n",
    "salary_df[\"M_PCT90\"] = (salary_df[\"a_pct90\"] / 12).round(2)\n",
    "\n",
    "# Education mapping\n",
    "edu_map = {\n",
    "    \"Less_than_hs\": \"LESS_THAN_HS\",\n",
    "    \"hs_or_eq\": \"HIGH_SCHOOL\",\n",
    "    \"Associate_degree\": \"ASSOCIATE\",\n",
    "    \"Bachelor_degree\": \"BACHELOR\",\n",
    "    \"Master_degree\": \"MASTERS\",\n",
    "    \"Doctorate_degree\": \"DOCTORATE\",\n",
    "    \"No_requirement\": \"NO_REQ\",\n",
    "    \"Professional_degree\": \"PROFESSIONAL\"\n",
    "}\n",
    "\n",
    "# Build records\n",
    "records = []\n",
    "grouped_salary = salary_df.groupby([\"occ_code\", \"year\"])\n",
    "\n",
    "for (soc_code, year), group in grouped_salary:\n",
    "    existing_record = next((r for r in records if r[\"soc_code\"] == soc_code), None)\n",
    "\n",
    "    if not existing_record:\n",
    "        existing_record = {\n",
    "            \"soc_code\": soc_code,\n",
    "            \"title\": group.iloc[0][\"occ_title\"],\n",
    "            \"description\": \"\",\n",
    "            \"salary\": {},\n",
    "            \"education\": {key: \"\" for key in edu_map.values()},\n",
    "            \"typicalSkills\": []\n",
    "        }\n",
    "        records.append(existing_record)\n",
    "\n",
    "    year_str = str(year)\n",
    "    existing_record[\"salary\"].setdefault(year_str, {})\n",
    "\n",
    "    for _, row in group.iterrows():\n",
    "        state = row[\"area_title\"]\n",
    "        industry = row[\"naics_title\"]\n",
    "        existing_record[\"salary\"][year_str].setdefault(state, {})[industry] = {\n",
    "            \"A_MEDIAN\": float(row[\"a_median\"]),\n",
    "            \"M_PCT10\": float(row[\"M_PCT10\"]),\n",
    "            \"M_MEDIAN\": float(row[\"M_MEDIAN\"]),\n",
    "            \"M_PCT90\": float(row[\"M_PCT90\"])\n",
    "        }\n",
    "\n",
    "# Add education data\n",
    "for record in records:\n",
    "    soc_code = record[\"soc_code\"]\n",
    "    edu_rows = education_df[(education_df[\"SOC\"] == soc_code) | (education_df[\"SOC\"] == \"00-0000\")]\n",
    "    for _, edu_row in edu_rows.iterrows():\n",
    "        est_code = edu_row[\"ESTIMATECODE\"]\n",
    "        est_value = str(edu_row[\"ESTIMATE\"])\n",
    "        if est_code in edu_map:\n",
    "            record[\"education\"][edu_map[est_code]] = est_value\n",
    "\n",
    "# Add skills data\n",
    "for record in records:\n",
    "    soc_code = record[\"soc_code\"]\n",
    "    skills_row = skills_df[skills_df[\"SOC_CODE\"] == soc_code]\n",
    "    if not skills_row.empty:\n",
    "        raw_skills = skills_row.iloc[0][\"TYPICAL_SKILLS\"].replace(\"'\", \"\\\"\")\n",
    "        try:\n",
    "            skills_list = json.loads(raw_skills)\n",
    "            record[\"typicalSkills\"] = sorted(set(skills_list))\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"⚠️ Error decoding skills for SOC {soc_code}\")\n",
    "            record[\"typicalSkills\"] = []\n",
    "\n",
    "# Write to output CSV\n",
    "output_file = \"soc_compiled_output.csv\"\n",
    "with open(output_file, \"w\", newline='', encoding=\"utf-8\") as csvfile:\n",
    "    fieldnames = [\"soc_code\", \"title\", \"description\", \"salary\", \"education\", \"typicalSkills\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for rec in records:\n",
    "        writer.writerow({\n",
    "            \"soc_code\": rec[\"soc_code\"],\n",
    "            \"title\": rec[\"title\"],\n",
    "            \"description\": rec[\"description\"],\n",
    "            \"salary\": json.dumps(rec[\"salary\"]),\n",
    "            \"education\": json.dumps(rec[\"education\"]),\n",
    "            \"typicalSkills\": json.dumps(rec[\"typicalSkills\"])\n",
    "        })\n",
    "\n",
    "print(f\"✅ Done! Output written to '{output_file}' with {len(records)} SOC records.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
