{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading education file: [Errno 2] No such file or directory: 'Datasets/ors_data.csv'\n",
      "Error loading skills file: [Errno 2] No such file or directory: 'Datasets/grouped_skills.csv'\n",
      "\n",
      "üîÑ Processing year: 2016\n",
      "Error loading Datasets/2016/national_2016.csv: [Errno 2] No such file or directory: 'Datasets/2016/national_2016.csv'\n",
      "Error loading Datasets/2016/state_2016.csv: [Errno 2] No such file or directory: 'Datasets/2016/state_2016.csv'\n",
      "Error loading Datasets/2016/industry_2016.csv: [Errno 2] No such file or directory: 'Datasets/2016/industry_2016.csv'\n",
      "Error loading Datasets/2016/allsectors_2016.csv: [Errno 2] No such file or directory: 'Datasets/2016/allsectors_2016.csv'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 207\u001b[0m\n\u001b[1;32m    204\u001b[0m     records_industry \u001b[38;5;241m=\u001b[39m process_industry(industry_df, year, education_data)\n\u001b[1;32m    205\u001b[0m     records_allsectors \u001b[38;5;241m=\u001b[39m process_allsectors(allsectors_df, year, education_data)\n\u001b[0;32m--> 207\u001b[0m     merged \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrecords_national\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecords_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecords_industry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecords_allsectors\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m     combined_records\u001b[38;5;241m.\u001b[39mappend(merged)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# Merge across all years\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 140\u001b[0m, in \u001b[0;36mmerge_records\u001b[0;34m(record_sets)\u001b[0m\n\u001b[1;32m    138\u001b[0m merged \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record_set \u001b[38;5;129;01min\u001b[39;00m record_sets:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrecord_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m merged:\n\u001b[1;32m    142\u001b[0m             merged[key] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_file(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, low_memory=False)\n",
    "        df = clean_column_names(df)\n",
    "        df = normalize_column_aliases(df)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_education(base_path='Datasets/'): \n",
    "    try:\n",
    "        edu_df = pd.read_csv(os.path.join(base_path, 'ors_data.csv'), dtype=str, low_memory=False)\n",
    "        edu_df = clean_column_names(edu_df)\n",
    "\n",
    "        if 'SOC' not in edu_df.columns or 'ESTIMATECODE' not in edu_df.columns or 'ESTIMATE' not in edu_df.columns:\n",
    "            print(\"‚ùå Required columns not found in ORS file.\")\n",
    "            return {}\n",
    "\n",
    "        # Define mapping from raw ESTIMATECODE to standard keys\n",
    "        code_map = {\n",
    "            'Less_than_hs': 'LESS_THAN_HS',\n",
    "            'hs_or_eq': 'HIGH_SCHOOL',\n",
    "            'Associate_degree': 'ASSOCIATE',\n",
    "            'Bachelor_degree': 'BACHELOR',\n",
    "            'Master_degree': 'MASTERS',\n",
    "            'Doctorate_degree': 'DOCTORATE',\n",
    "            'No_requirement': 'NO_REQ',\n",
    "            'Professional_degree': 'PROFESSIONAL'\n",
    "        }\n",
    "\n",
    "        edu_df = edu_df[edu_df['ESTIMATECODE'].isin(code_map.keys())]\n",
    "        edu_df['ESTIMATECODE'] = edu_df['ESTIMATECODE'].map(code_map)\n",
    "\n",
    "        # Remove < signs and convert to numeric safely\n",
    "        edu_df['ESTIMATE'] = edu_df['ESTIMATE'].str.replace('<', '', regex=False).str.strip()\n",
    "\n",
    "        pivot_df = edu_df.pivot_table(index='SOC', columns='ESTIMATECODE', values='ESTIMATE', aggfunc='first').fillna('')\n",
    "        pivot_df.index.name = 'OCC_CODE'\n",
    "\n",
    "        return pivot_df.to_dict('index')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading education file: {e}\")\n",
    "        return {}\n",
    "\n",
    "def clean_column_names(df):\n",
    "    df.columns = [c.strip().upper().replace(' ', '_') for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def normalize_column_aliases(df):\n",
    "    column_renames = {\n",
    "        'STATE': 'AREA_TITLE',\n",
    "        'area_title': 'AREA_TITLE',\n",
    "        'naics_title': 'NAICS_TITLE'\n",
    "    }\n",
    "    df.rename(columns={k: v for k, v in column_renames.items() if k in df.columns}, inplace=True)\n",
    "    return df\n",
    "\n",
    "def process_national(df, year, education_data):\n",
    "    return process_generic(df, year, education_data, area_col='AREA_TITLE', industry_col=None, industry_default='Cross-industry')\n",
    "\n",
    "def process_state(df, year, education_data):\n",
    "    return process_generic(df, year, education_data, area_col='AREA_TITLE', industry_col=None, industry_default='Cross-industry')\n",
    "\n",
    "def process_industry(df, year, education_data):\n",
    "    return process_generic(df, year, education_data, area_col='AREA_TITLE', industry_col='NAICS_TITLE', industry_default='Unknown')\n",
    "\n",
    "def process_allsectors(df, year, education_data):\n",
    "    return process_generic(df, year, education_data, area_col='AREA_TITLE', industry_col=None, industry_default='Cross-industry')\n",
    "\n",
    "def process_generic(df, year, education_data, area_col='AREA_TITLE', industry_col=None, industry_default=None):\n",
    "    records = {}\n",
    "    for _, row in df.iterrows():\n",
    "        occ_code = str(row.get('OCC_CODE', '')).strip()\n",
    "        occ_title = str(row.get('OCC_TITLE', '')).strip()\n",
    "        area = str(row.get(area_col, 'U.S.')).strip()\n",
    "        industry = str(row.get(industry_col, industry_default)) if industry_col else industry_default\n",
    "\n",
    "        if not occ_code:\n",
    "            continue\n",
    "\n",
    "        key = (occ_code, occ_title)\n",
    "\n",
    "        if key not in records:\n",
    "            education_entry = education_data.get(occ_code, {})\n",
    "            records[key] = {\n",
    "                'occ_code': occ_code,\n",
    "                'occ_title': occ_title,\n",
    "                'salary': {},\n",
    "                'education': {\n",
    "                    'LESS_THAN_HS': education_entry.get('LESS_THAN_HS', ''),\n",
    "                    'HIGH_SCHOOL': education_entry.get('HIGH_SCHOOL', ''),\n",
    "                    'ASSOCIATE': education_entry.get('ASSOCIATE', ''),\n",
    "                    'BACHELOR': education_entry.get('BACHELOR', ''),\n",
    "                    'MASTERS': education_entry.get('MASTERS', ''),\n",
    "                    'DOCTORATE': education_entry.get('DOCTORATE', ''),\n",
    "                    'NO_REQ': education_entry.get('NO_REQ', ''),\n",
    "                    'PROFESSIONAL': education_entry.get('PROFESSIONAL', '')\n",
    "                }\n",
    "            }\n",
    "\n",
    "        salary_entry = {\n",
    "            'A_MEDIAN': try_float(row.get('A_MEDIAN')),\n",
    "            'M_PCT10': safe_divide_by_12(row.get('A_PCT10', '')),\n",
    "            'M_MEDIAN': safe_divide_by_12(row.get('A_MEDIAN', '')),\n",
    "            'M_PCT90': safe_divide_by_12(row.get('A_PCT90', '')),\n",
    "        }\n",
    "\n",
    "        if area not in records[key]['salary']:\n",
    "            records[key]['salary'][area] = {}\n",
    "\n",
    "        if year not in records[key]['salary']:\n",
    "            records[key]['salary'][year] = {}\n",
    "        if area not in records[key]['salary'][year]:\n",
    "            records[key]['salary'][year][area] = {}\n",
    "            records[key]['salary'][year][area][industry] = salary_entry\n",
    "    \n",
    "        return records\n",
    "\n",
    "def try_float(val):\n",
    "    try:\n",
    "        return float(val)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "    \n",
    "def safe_divide_by_12(value):\n",
    "    try:\n",
    "        return str(round(float(value) / 12, 2))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def merge_records(record_sets):\n",
    "    merged = {}\n",
    "    for record_set in record_sets:\n",
    "        for key, value in record_set.items():\n",
    "            if key not in merged:\n",
    "                merged[key] = value\n",
    "            else:\n",
    "                for area, industries in value['salary'].items():\n",
    "                    if area not in merged[key]['salary']:\n",
    "                        merged[key]['salary'][area] = {}\n",
    "                    merged[key]['salary'][area].update(industries)\n",
    "    return merged\n",
    "\n",
    "def generate_output(merged_records, output_csv_path):\n",
    "    output_rows = []\n",
    "\n",
    "    for record in merged_records.values():\n",
    "        output_rows.append({\n",
    "            'occ_code': record['occ_code'],\n",
    "            'occ_title': record['occ_title'],\n",
    "            'salary': json.dumps(record['salary']).replace('\"', '\\\\\"'),\n",
    "            'education': json.dumps(record['education']).replace('\"', '\\\\\"')\n",
    "        })\n",
    "\n",
    "    df_output = pd.DataFrame(output_rows)\n",
    "    df_output.to_csv(output_csv_path, index=False)\n",
    "    print(f\"‚úÖ Output CSV generated: {output_csv_path}\")\n",
    "\n",
    "def load_skills(filepath='Datasets/grouped_skills.csv'):\n",
    "    try:\n",
    "        skills_df = pd.read_csv(filepath, dtype=str, low_memory=False)\n",
    "        skills_df = clean_column_names(skills_df)\n",
    "        print (f\"‚úÖ Skills file loaded: {skills_df.columns}\")\n",
    "        # Ensure column names are consistent\n",
    "        # Check for the presence of 'SOC_CODE' or 'SOC' columns\n",
    "        if 'SOC_CODE' not in skills_df.columns and 'SOC' not in skills_df.columns:\n",
    "            print(f\"‚ùå 'SOC_CODE' or 'SOC' column not found in skills file. Available columns: {skills_df.columns.tolist()}\")\n",
    "            return {}\n",
    "        if 'SOC' in skills_df.columns:\n",
    "            skills_df.rename(columns={'SOC': 'SOC_CODE'}, inplace=True)\n",
    "\n",
    "        if 'TYPICAL_SKILLS' not in skills_df.columns:\n",
    "            print(\"‚ùå 'TYPICAL_SKILLS' column not found in skills file.\")\n",
    "            return {}\n",
    "\n",
    "        skills_map = skills_df.set_index('SOC_CODE')['TYPICAL_SKILLS'].to_dict()\n",
    "        return skills_map\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading skills file: {e}\")\n",
    "        return {}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    combined_records = []\n",
    "    education_data = load_education()  # Load once for all years\n",
    "    skills_data = load_skills()  # Load skills data\n",
    "\n",
    "    for year in range(2016, 2017):\n",
    "        print(f\"\\nüîÑ Processing year: {year}\")\n",
    "        base_path = f'Datasets/{year}'\n",
    "        \n",
    "        national_df = load_file(os.path.join(base_path, f'national_{year}.csv'))\n",
    "        state_df = load_file(os.path.join(base_path, f'state_{year}.csv'))\n",
    "        industry_df = load_file(os.path.join(base_path, f'industry_{year}.csv'))\n",
    "        allsectors_df = load_file(os.path.join(base_path, f'allsectors_{year}.csv'))\n",
    "\n",
    "        records_national = process_national(national_df, year, education_data)\n",
    "        records_state = process_state(state_df, year, education_data)\n",
    "        records_industry = process_industry(industry_df, year, education_data)\n",
    "        records_allsectors = process_allsectors(allsectors_df, year, education_data)\n",
    "\n",
    "        merged = merge_records([records_national, records_state, records_industry, records_allsectors])\n",
    "        combined_records.append(merged)\n",
    "\n",
    "    # Merge across all years\n",
    "    all_years_merged = merge_records(combined_records)\n",
    "\n",
    "    # Append skills data to the merged records\n",
    "    for key, record in all_years_merged.items():\n",
    "        occ_code = record['occ_code']\n",
    "        record['TYPICAL_SKILLS'] = skills_data.get(occ_code, '')\n",
    "\n",
    "    output_path = 'dynamodb_insert_2016_2024_combined.csv'\n",
    "    generate_output(all_years_merged, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
