{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "#                DYNAMODB TABLES\n",
    "# ==================================================\n",
    "API_ID = \"alek4h7jlreffeoe5tocxgnx2u\"\n",
    "CAREER_SALARY_TABLE      = f\"careerSalary-{API_ID}-NONE\"\n",
    "CAREER_EDUCATION_TABLE   = \"careerEducation-{API_ID}-NONE\"\n",
    "CAREER_SKILLS_TABLE      = \"careerSkills-{API_ID}-NONE\"\n",
    "CAREER_DESCRIPTION_TABLE = \"careerDescription-{API_ID}-NONE\"\n",
    "SOC_CODES_TABLE          = \"socCodes-{API_ID}-NONE\"\n",
    "REGION = \"us-west-2\"\n",
    "NUM_THREADS = 4\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import ast\n",
    "import time\n",
    "import threading\n",
    "from decimal import Decimal\n",
    "from collections import defaultdict\n",
    "from queue import Queue\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "dynamodb = boto3.resource(\"dynamodb\", region_name=REGION)\n",
    "\n",
    "# ==================================================\n",
    "#              COMMON UTILS / THREADING\n",
    "# ==================================================\n",
    "\n",
    "class DynamoUploader:\n",
    "    def __init__(self, table, batch_size, rejected_file, overwrite_pkeys):\n",
    "        self.table = table\n",
    "        self.batch_size = batch_size\n",
    "        self.rejected_file = rejected_file\n",
    "        self.queue = Queue()\n",
    "        self.rejected_rows = []\n",
    "        self.lock = threading.Lock()\n",
    "        self.overwrite_pkeys = overwrite_pkeys\n",
    "\n",
    "    def process_batch(self, batch, batch_number):\n",
    "        start = time.time()\n",
    "        try:\n",
    "            with self.table.batch_writer(overwrite_by_pkeys=self.overwrite_pkeys) as writer:\n",
    "                for item in batch:\n",
    "                    try:\n",
    "                        writer.put_item(Item=item)\n",
    "                    except Exception as e:\n",
    "                        with self.lock:\n",
    "                            self.rejected_rows.append({**item, 'error': str(e)})\n",
    "            print(f\"✅ Batch {batch_number} inserted in {time.time() - start:.2f}s ({len(batch)} records)\")\n",
    "        except Exception as e:\n",
    "            with self.lock:\n",
    "                for item in batch:\n",
    "                    self.rejected_rows.append({**item, 'error': str(e)})\n",
    "            print(f\"❌ Batch {batch_number} failed with error: {str(e)}\")\n",
    "\n",
    "    def worker(self):\n",
    "        batch_number = 1\n",
    "        while True:\n",
    "            batch = self.queue.get()\n",
    "            if batch is None:\n",
    "                break\n",
    "            self.process_batch(batch, batch_number)\n",
    "            batch_number += 1\n",
    "            self.queue.task_done()\n",
    "\n",
    "    def threaded_upload(self, data_iter):\n",
    "        threads = []\n",
    "        for _ in range(NUM_THREADS):\n",
    "            t = threading.Thread(target=self.worker)\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "        for batch in data_iter:\n",
    "            self.queue.put(batch)\n",
    "        self.queue.join()\n",
    "        for _ in range(NUM_THREADS):\n",
    "            self.queue.put(None)\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "    def save_rejected_rows(self):\n",
    "        if self.rejected_rows:\n",
    "            keys = self.rejected_rows[0].keys()\n",
    "            with open(self.rejected_file, 'w', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=keys)\n",
    "                writer.writeheader()\n",
    "                writer.writerows(self.rejected_rows)\n",
    "            print(f\"⚠️ {len(self.rejected_rows)} records rejected. Saved to {self.rejected_file}\")\n",
    "\n",
    "# ==================================================\n",
    "#         HELPERS FOR EACH DATA TYPE\n",
    "# ==================================================\n",
    "def to_decimal(val):\n",
    "    try:\n",
    "        return Decimal(str(round(float(val), 2))) if val not in [None, '', 'null'] else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def batch_iterable(iterable, batch_size):\n",
    "    batch = []\n",
    "    for item in iterable:\n",
    "        batch.append(item)\n",
    "        if len(batch) == batch_size:\n",
    "            yield batch\n",
    "            batch = []\n",
    "    if batch:\n",
    "        yield batch\n",
    "\n",
    "# -------- CAREER SALARY --------\n",
    "def salary_data_iter(directory, batch_size):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"_dynamodb_ready.csv\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, mode='r', encoding='utf-8') as f:\n",
    "                reader = csv.DictReader(f)\n",
    "                batch = []\n",
    "                for row in reader:\n",
    "                    try:\n",
    "                        item = {\n",
    "                            'occ_code': str(row['occ_code']),\n",
    "                            'salary_key': str(row['salary_key']),\n",
    "                            'a_median': to_decimal(row.get('a_median')),\n",
    "                            'm_median': to_decimal(row.get('m_median')),\n",
    "                            'm_pct10': to_decimal(row.get('m_pct10')),\n",
    "                            'm_pct90': to_decimal(row.get('m_pct90')),\n",
    "                        }\n",
    "                        item = {k: v for k, v in item.items() if v is not None}\n",
    "                        batch.append(item)\n",
    "                        if len(batch) == batch_size:\n",
    "                            yield batch\n",
    "                            batch = []\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "                if batch:\n",
    "                    yield batch\n",
    "\n",
    "# -------- CAREER EDUCATION --------\n",
    "def education_data_iter(input_file, batch_size):\n",
    "    CODE_TO_FIELD = {\n",
    "        'Less_than_hs': 'less_than_highschool',\n",
    "        'hs_or_eq': 'high_school_or_equivalent',\n",
    "        'Associate_degree': 'associate_degree',\n",
    "        'Bachelor_degree': 'bachelor_degree',\n",
    "        'Master_degree': 'master_degree',\n",
    "        'Doctorate_degree': 'doctorate_degree',\n",
    "        'No_requirement': 'no_requirement',\n",
    "        'Professional_degree': 'professional_degree',\n",
    "    }\n",
    "    edu_data = defaultdict(dict)\n",
    "    with open(input_file, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            occ = row['SOC']\n",
    "            code = row['ESTIMATECODE']\n",
    "            field = CODE_TO_FIELD.get(code)\n",
    "            if not field:\n",
    "                continue\n",
    "            value = row['ESTIMATE']\n",
    "            edu_data[occ].setdefault('occ_code', occ)\n",
    "            edu_data[occ][field] = value\n",
    "    return batch_iterable(edu_data.values(), batch_size)\n",
    "\n",
    "# -------- CAREER SKILLS --------\n",
    "def skills_data_iter(input_file, batch_size):\n",
    "    with open(input_file, mode='r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        batch = []\n",
    "        for row_num, row in enumerate(reader, 2):\n",
    "            try:\n",
    "                occ_code = str(row['SOC_CODE'])\n",
    "                skills_str = row['TYPICAL_SKILLS']\n",
    "                skills = ast.literal_eval(skills_str)\n",
    "                item = {'occ_code': occ_code, 'skills': skills}\n",
    "                batch.append(item)\n",
    "                if len(batch) == batch_size:\n",
    "                    yield batch\n",
    "                    batch = []\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        if batch:\n",
    "            yield batch\n",
    "\n",
    "# -------- CAREER DESCRIPTION --------\n",
    "def description_data_iter(input_file, batch_size):\n",
    "    with open(input_file, mode='r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        batch = []\n",
    "        for row_num, row in enumerate(reader, 2):\n",
    "            try:\n",
    "                item = {'occ_code': str(row['Code']), 'description': str(row['Description'])}\n",
    "                batch.append(item)\n",
    "                if len(batch) == batch_size:\n",
    "                    yield batch\n",
    "                    batch = []\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        if batch:\n",
    "            yield batch\n",
    "\n",
    "# -------- SOC CODES --------\n",
    "def soc_codes_data_iter(input_file, batch_size):\n",
    "    with open(input_file, mode='r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        batch = []\n",
    "        for row_num, row in enumerate(reader, 2):\n",
    "            try:\n",
    "                item = {'occ_code': str(row['OCC_CODE']), 'occ_title': str(row['OCC_TITLE'])}\n",
    "                batch.append(item)\n",
    "                if len(batch) == batch_size:\n",
    "                    yield batch\n",
    "                    batch = []\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        if batch:\n",
    "            yield batch\n",
    "\n",
    "# ==================================================\n",
    "#                  MAIN RUNNER\n",
    "# ==================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Uploading Career Salary...\")\n",
    "    salary_uploader = DynamoUploader(\n",
    "        dynamodb.Table(CAREER_SALARY_TABLE), 1000, \"rejected_dynamodb_rows.csv\", ['occ_code']\n",
    "    )\n",
    "    salary_uploader.threaded_upload(salary_data_iter(\"Datasets/dynamodb_ready_by_year\", 1000))\n",
    "    salary_uploader.save_rejected_rows()\n",
    "    \n",
    "    print(f\"Uploading Career Education...\")\n",
    "    edu_uploader = DynamoUploader(\n",
    "        dynamodb.Table(CAREER_EDUCATION_TABLE), 100, \"rejected_career_education.csv\", ['occ_code']\n",
    "    )\n",
    "    edu_uploader.threaded_upload(education_data_iter(\"Datasets/education_data.csv\", 100))\n",
    "    edu_uploader.save_rejected_rows()\n",
    "    \n",
    "    print(f\"Uploading Career Skills...\")\n",
    "    skills_uploader = DynamoUploader(\n",
    "        dynamodb.Table(CAREER_SKILLS_TABLE), 100, \"rejected_career_skills.csv\", ['occ_code']\n",
    "    )\n",
    "    skills_uploader.threaded_upload(skills_data_iter(\"Datasets/skills_data.csv\", 100))\n",
    "    skills_uploader.save_rejected_rows()\n",
    "    \n",
    "    print(f\"Uploading Career Description...\")\n",
    "    desc_uploader = DynamoUploader(\n",
    "        dynamodb.Table(CAREER_DESCRIPTION_TABLE), 100, \"rejected_career_description.csv\", ['occ_code']\n",
    "    )\n",
    "    desc_uploader.threaded_upload(description_data_iter(\"Datasets/description.csv\", 100))\n",
    "    desc_uploader.save_rejected_rows()\n",
    "    \n",
    "    print(f\"Uploading SOC Codes...\")\n",
    "    soc_uploader = DynamoUploader(\n",
    "        dynamodb.Table(SOC_CODES_TABLE), 100, \"rejected_soc_codes.csv\", ['occ_code']\n",
    "    )\n",
    "    soc_uploader.threaded_upload(soc_codes_data_iter(\"Datasets/unique_occ_codes.csv\", 100))\n",
    "    soc_uploader.save_rejected_rows()\n",
    "    \n",
    "    print(\"🚀 ALL TABLES UPLOADED. YOU'RE DONE.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
