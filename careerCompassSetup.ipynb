{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8edf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Converting national_M_2016_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\national_M_2016_dl_dynamodb_ready.csv...\n",
      "✅ Wrote 1394 rows to Datasets/dynamodb_ready_by_year\\national_M_2016_dl_dynamodb_ready.csv\n",
      "🔄 Converting national_M_2017_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\national_M_2017_dl_dynamodb_ready.csv...\n",
      "✅ Wrote 1382 rows to Datasets/dynamodb_ready_by_year\\national_M_2017_dl_dynamodb_ready.csv\n",
      "🔄 Converting national_M_2018_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\national_M_2018_dl_dynamodb_ready.csv...\n",
      "✅ Wrote 1379 rows to Datasets/dynamodb_ready_by_year\\national_M_2018_dl_dynamodb_ready.csv\n",
      "🔄 Converting national_M_2019_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\national_M_2019_dl_dynamodb_ready.csv...\n",
      "✅ Wrote 1329 rows to Datasets/dynamodb_ready_by_year\\national_M_2019_dl_dynamodb_ready.csv\n",
      "🔄 Converting national_M_2020_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\national_M_2020_dl_dynamodb_ready.csv...\n",
      "✅ Wrote 1329 rows to Datasets/dynamodb_ready_by_year\\national_M_2020_dl_dynamodb_ready.csv\n",
      "🔄 Converting national_M_2021_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\national_M_2021_dl_dynamodb_ready.csv...\n",
      "✅ Wrote 1403 rows to Datasets/dynamodb_ready_by_year\\national_M_2021_dl_dynamodb_ready.csv\n",
      "🔄 Converting national_M_2022_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\national_M_2022_dl_dynamodb_ready.csv...\n",
      "✅ Wrote 1402 rows to Datasets/dynamodb_ready_by_year\\national_M_2022_dl_dynamodb_ready.csv\n",
      "🔄 Converting national_M_2023_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\national_M_2023_dl_dynamodb_ready.csv...\n",
      "✅ Wrote 1403 rows to Datasets/dynamodb_ready_by_year\\national_M_2023_dl_dynamodb_ready.csv\n",
      "🔄 Converting national_M_2024_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\national_M_2024_dl_dynamodb_ready.csv...\n",
      "✅ Wrote 1403 rows to Datasets/dynamodb_ready_by_year\\national_M_2024_dl_dynamodb_ready.csv\n",
      "🔄 Converting state_M_2016_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\state_M_2016_dl_dynamodb_ready.csv...\n",
      "   ...Processed 10000 rows so far in state_M_2016_dl.csv\n",
      "   ...Processed 20000 rows so far in state_M_2016_dl.csv\n",
      "   ...Processed 30000 rows so far in state_M_2016_dl.csv\n",
      "✅ Wrote 37561 rows to Datasets/dynamodb_ready_by_year\\state_M_2016_dl_dynamodb_ready.csv\n",
      "🔄 Converting state_M_2017_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\state_M_2017_dl_dynamodb_ready.csv...\n",
      "   ...Processed 10000 rows so far in state_M_2017_dl.csv\n",
      "   ...Processed 20000 rows so far in state_M_2017_dl.csv\n",
      "   ...Processed 30000 rows so far in state_M_2017_dl.csv\n",
      "✅ Wrote 36992 rows to Datasets/dynamodb_ready_by_year\\state_M_2017_dl_dynamodb_ready.csv\n",
      "🔄 Converting state_M_2018_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\state_M_2018_dl_dynamodb_ready.csv...\n",
      "   ...Processed 10000 rows so far in state_M_2018_dl.csv\n",
      "   ...Processed 20000 rows so far in state_M_2018_dl.csv\n",
      "   ...Processed 30000 rows so far in state_M_2018_dl.csv\n",
      "✅ Wrote 36897 rows to Datasets/dynamodb_ready_by_year\\state_M_2018_dl_dynamodb_ready.csv\n",
      "🔄 Converting state_M_2019_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\state_M_2019_dl_dynamodb_ready.csv...\n",
      "   ...Processed 10000 rows so far in state_M_2019_dl.csv\n",
      "   ...Processed 20000 rows so far in state_M_2019_dl.csv\n",
      "   ...Processed 30000 rows so far in state_M_2019_dl.csv\n",
      "✅ Wrote 36382 rows to Datasets/dynamodb_ready_by_year\\state_M_2019_dl_dynamodb_ready.csv\n",
      "🔄 Converting state_M_2020_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\state_M_2020_dl_dynamodb_ready.csv...\n",
      "   ...Processed 10000 rows so far in state_M_2020_dl.csv\n",
      "   ...Processed 20000 rows so far in state_M_2020_dl.csv\n",
      "   ...Processed 30000 rows so far in state_M_2020_dl.csv\n",
      "✅ Wrote 36085 rows to Datasets/dynamodb_ready_by_year\\state_M_2020_dl_dynamodb_ready.csv\n",
      "🔄 Converting state_M_2021_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\state_M_2021_dl_dynamodb_ready.csv...\n",
      "   ...Processed 10000 rows so far in state_M_2021_dl.csv\n",
      "   ...Processed 20000 rows so far in state_M_2021_dl.csv\n",
      "   ...Processed 30000 rows so far in state_M_2021_dl.csv\n",
      "✅ Wrote 37580 rows to Datasets/dynamodb_ready_by_year\\state_M_2021_dl_dynamodb_ready.csv\n",
      "🔄 Converting state_M_2022_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\state_M_2022_dl_dynamodb_ready.csv...\n",
      "   ...Processed 10000 rows so far in state_M_2022_dl.csv\n",
      "   ...Processed 20000 rows so far in state_M_2022_dl.csv\n",
      "   ...Processed 30000 rows so far in state_M_2022_dl.csv\n",
      "✅ Wrote 37569 rows to Datasets/dynamodb_ready_by_year\\state_M_2022_dl_dynamodb_ready.csv\n",
      "🔄 Converting state_M_2023_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\state_M_2023_dl_dynamodb_ready.csv...\n",
      "   ...Processed 10000 rows so far in state_M_2023_dl.csv\n",
      "   ...Processed 20000 rows so far in state_M_2023_dl.csv\n",
      "   ...Processed 30000 rows so far in state_M_2023_dl.csv\n",
      "✅ Wrote 37676 rows to Datasets/dynamodb_ready_by_year\\state_M_2023_dl_dynamodb_ready.csv\n",
      "🔄 Converting state_M_2024_dl.csv to DynamoDB format as Datasets/dynamodb_ready_by_year\\state_M_2024_dl_dynamodb_ready.csv...\n",
      "   ...Processed 10000 rows so far in state_M_2024_dl.csv\n",
      "   ...Processed 20000 rows so far in state_M_2024_dl.csv\n",
      "   ...Processed 30000 rows so far in state_M_2024_dl.csv\n",
      "✅ Wrote 36844 rows to Datasets/dynamodb_ready_by_year\\state_M_2024_dl_dynamodb_ready.csv\n",
      "\n",
      "🎯 All files converted and saved to: Datasets/dynamodb_ready_by_year\n"
     ]
    }
   ],
   "source": [
    "# No DynamoDB table used in this part.\n",
    "\n",
    "# 1. Convert all XLSX files in the salary directory to CSV\n",
    "import os\n",
    "import csv\n",
    "from openpyxl import load_workbook\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "\n",
    "input_dir = \"Datasets/salary\"\n",
    "output_dir = \"Datasets/csv_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print_lock = threading.Lock()\n",
    "\n",
    "def log(msg):\n",
    "    with print_lock:\n",
    "        print(msg)\n",
    "\n",
    "def convert_file(filename):\n",
    "    if not filename.endswith(\".xlsx\"):\n",
    "        return\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    output_filename = os.path.splitext(filename)[0] + \".csv\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    log(f\"🔄 START: {filename}\")\n",
    "    try:\n",
    "        wb = load_workbook(filename=input_path, read_only=True)\n",
    "        ws = wb.active\n",
    "        with open(output_path, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for row in ws.iter_rows(values_only=True):\n",
    "                writer.writerow(row)\n",
    "        log(f\"✅ DONE:  {filename} → {output_filename}\")\n",
    "    except Exception as e:\n",
    "        log(f\"❌ ERROR: {filename}: {e}\")\n",
    "\n",
    "files = [f for f in os.listdir(input_dir) if f.endswith(\".xlsx\")]\n",
    "\n",
    "log(f\"\\n🚀 Processing {len(files)} files from '{input_dir}' to '{output_dir}'...\\n\")\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.map(convert_file, files)\n",
    "log(\"\\n🎯 All XLSX files processed.\\n\")\n",
    "\n",
    "# 2. Convert the resulting CSV files to DynamoDB-ready format\n",
    "import os\n",
    "import csv\n",
    "\n",
    "input_dir = \"Datasets/csv_output\"\n",
    "output_dir = \"Datasets/dynamodb_ready_by_year\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "fieldnames = [\n",
    "    \"occ_code\",\n",
    "    \"salary_key\",\n",
    "    \"a_median\",\n",
    "    \"m_median\",\n",
    "    \"m_pct10\",\n",
    "    \"m_pct90\"\n",
    "]\n",
    "\n",
    "def safe_div(val):\n",
    "    try:\n",
    "        f = float(val)\n",
    "        return f\"{f / 12:.2f}\"\n",
    "    except (ValueError, TypeError):\n",
    "        return \"\"\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    # Extract year from filename, else \"unknown\"\n",
    "    basename = os.path.splitext(filename)[0]\n",
    "    year = None\n",
    "    for part in basename.split('_'):\n",
    "        if part.isdigit() and len(part) == 4:\n",
    "            year = part\n",
    "            break\n",
    "    if not year:\n",
    "        year = \"unknown\"\n",
    "\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    output_path = os.path.join(output_dir, f\"{basename}_dynamodb_ready.csv\")\n",
    "\n",
    "    print(f\"🔄 Converting {filename} to DynamoDB format as {output_path}...\")\n",
    "\n",
    "    with open(input_path, mode='r', encoding='utf-8') as infile, \\\n",
    "         open(output_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "\n",
    "        reader = csv.DictReader(infile)\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        count = 0\n",
    "        log_interval = 10000\n",
    "\n",
    "        for row_num, row in enumerate(reader, 2):\n",
    "            try:\n",
    "                occ_code = row.get('occ_code') or row.get('OCC_CODE')\n",
    "                a_median = row.get('a_median') or row.get('A_MEDIAN')\n",
    "                a_pct10 = row.get('a_pct10') or row.get('A_PCT10')\n",
    "                a_pct90 = row.get('a_pct90') or row.get('A_PCT90')\n",
    "                # Convert to float if possible; otherwise, default to 0\n",
    "                try:\n",
    "                    a_median = float(a_median)\n",
    "                except (TypeError, ValueError):\n",
    "                    a_median = 0\n",
    "\n",
    "                # Key fields\n",
    "                area_title = row.get('area_title') or row.get('AREA_TITLE') or 'U.S.'\n",
    "                naics_title = row.get('naics_title') or row.get('NAICS_TITLE') or 'Cross-Industry'\n",
    "                salary_key = f\"{year}#{area_title}#{naics_title}\"\n",
    "\n",
    "                m_median = safe_div(a_median)\n",
    "                m_pct10 = safe_div(a_pct10)\n",
    "                m_pct90 = safe_div(a_pct90)\n",
    "\n",
    "                writer.writerow({\n",
    "                    \"occ_code\": occ_code,\n",
    "                    \"salary_key\": salary_key,\n",
    "                    \"a_median\": a_median,\n",
    "                    \"m_median\": m_median,\n",
    "                    \"m_pct10\": m_pct10,\n",
    "                    \"m_pct90\": m_pct90,\n",
    "                })\n",
    "                count += 1\n",
    "\n",
    "                if count % log_interval == 0:\n",
    "                    print(f\"   ...Processed {count} rows so far in {filename}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Failed on row {row_num} in {filename}: {e}\")\n",
    "\n",
    "    print(f\"✅ Wrote {count} rows to {output_path}\")\n",
    "\n",
    "print(\"\\n🎯 All files converted and saved to:\", output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
