{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8edf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No DynamoDB table used in this part.\n",
    "\n",
    "# 1. Convert all XLSX files in the salary directory to CSV\n",
    "import os\n",
    "import csv\n",
    "from openpyxl import load_workbook\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "\n",
    "input_dir = \"Datasets/salary\"\n",
    "output_dir = \"Datasets/csv_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print_lock = threading.Lock()\n",
    "\n",
    "def log(msg):\n",
    "    with print_lock:\n",
    "        print(msg)\n",
    "\n",
    "def convert_file(filename):\n",
    "    if not filename.endswith(\".xlsx\"):\n",
    "        return\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    output_filename = os.path.splitext(filename)[0] + \".csv\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    log(f\"üîÑ START: {filename}\")\n",
    "    try:\n",
    "        wb = load_workbook(filename=input_path, read_only=True)\n",
    "        ws = wb.active\n",
    "        with open(output_path, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for row in ws.iter_rows(values_only=True):\n",
    "                writer.writerow(row)\n",
    "        log(f\"‚úÖ DONE:  {filename} ‚Üí {output_filename}\")\n",
    "    except Exception as e:\n",
    "        log(f\"‚ùå ERROR: {filename}: {e}\")\n",
    "\n",
    "files = [f for f in os.listdir(input_dir) if f.endswith(\".xlsx\")]\n",
    "\n",
    "log(f\"\\nüöÄ Processing {len(files)} files from '{input_dir}' to '{output_dir}'...\\n\")\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.map(convert_file, files)\n",
    "log(\"\\nüéØ All XLSX files processed.\\n\")\n",
    "\n",
    "# 2. Convert the resulting CSV files to DynamoDB-ready format\n",
    "import os\n",
    "import csv\n",
    "\n",
    "input_dir = \"Datasets/csv_output\"\n",
    "output_dir = \"Datasets/dynamodb_ready_by_year\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "fieldnames = [\n",
    "    \"occ_code\",\n",
    "    \"salary_key\",\n",
    "    \"a_median\",\n",
    "    \"m_median\",\n",
    "    \"m_pct10\",\n",
    "    \"m_pct90\"\n",
    "]\n",
    "\n",
    "def safe_div(val):\n",
    "    try:\n",
    "        f = float(val)\n",
    "        return f\"{f / 12:.2f}\"\n",
    "    except (ValueError, TypeError):\n",
    "        return \"\"\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    # Extract year from filename, else \"unknown\"\n",
    "    basename = os.path.splitext(filename)[0]\n",
    "    year = None\n",
    "    for part in basename.split('_'):\n",
    "        if part.isdigit() and len(part) == 4:\n",
    "            year = part\n",
    "            break\n",
    "    if not year:\n",
    "        year = \"unknown\"\n",
    "\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    output_path = os.path.join(output_dir, f\"{basename}_dynamodb_ready.csv\")\n",
    "\n",
    "    print(f\"üîÑ Converting {filename} to DynamoDB format as {output_path}...\")\n",
    "\n",
    "    with open(input_path, mode='r', encoding='utf-8') as infile, \\\n",
    "         open(output_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "\n",
    "        reader = csv.DictReader(infile)\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        count = 0\n",
    "        log_interval = 10000\n",
    "\n",
    "        for row_num, row in enumerate(reader, 2):\n",
    "            try:\n",
    "                occ_code = row.get('occ_code') or row.get('OCC_CODE')\n",
    "                a_median = row.get('a_median') or row.get('A_MEDIAN')\n",
    "                a_pct10 = row.get('a_pct10') or row.get('A_PCT10')\n",
    "                a_pct90 = row.get('a_pct90') or row.get('A_PCT90')\n",
    "                # Key fields\n",
    "                area_title = row.get('area_title') or row.get('AREA_TITLE')\n",
    "                naics_title = row.get('naics_title') or row.get('NAICS_TITLE')\n",
    "                salary_key = f\"{year}#{area_title}#{naics_title}\"\n",
    "\n",
    "                m_median = safe_div(a_median)\n",
    "                m_pct10 = safe_div(a_pct10)\n",
    "                m_pct90 = safe_div(a_pct90)\n",
    "\n",
    "                writer.writerow({\n",
    "                    \"occ_code\": occ_code,\n",
    "                    \"salary_key\": salary_key,\n",
    "                    \"a_median\": a_median,\n",
    "                    \"m_median\": m_median,\n",
    "                    \"m_pct10\": m_pct10,\n",
    "                    \"m_pct90\": m_pct90,\n",
    "                })\n",
    "                count += 1\n",
    "\n",
    "                if count % log_interval == 0:\n",
    "                    print(f\"   ...Processed {count} rows so far in {filename}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed on row {row_num} in {filename}: {e}\")\n",
    "\n",
    "    print(f\"‚úÖ Wrote {count} rows to {output_path}\")\n",
    "\n",
    "print(\"\\nüéØ All files converted and saved to:\", output_dir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
